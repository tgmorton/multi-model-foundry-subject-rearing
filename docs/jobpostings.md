Research Engineer, Model Evaluations
San Francisco, CA | New York City, NY
About Anthropic

Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the role

As a Research Engineer on the Model Evaluations team, you'll lead the design and implementation of Anthropic's evaluation platform—a critical system that shapes how we understand, measure, and improve our models' capabilities and safety. You'll work at the intersection of research and engineering to develop and implement model evaluations that give us insight into emerging capabilities and build robust evaluation infrastructure that directly influences our training decisions and model development roadmap.

Your work will be essential to Anthropic's mission of building safe, beneficial AI systems. You'll collaborate closely with training teams, alignment researchers, and safety teams to ensure our models meet the highest standards before deployment. This is a technical leadership role where you'll drive both the strategic vision and hands-on implementation of our evaluation systems.

Responsibilities

Design novel evaluation methodologies to assess model capabilities across diverse domains including reasoning, safety, helpfulness, and harmlessness
Lead the design and architecture of Anthropic's evaluation platform, ensuring it scales with our rapidly evolving model capabilities and research needs
Implement and maintain high-throughput evaluation pipelines that run during production training, providing real-time insights to guide training decisions
Analyze evaluation results to identify patterns, failure modes, and opportunities for model improvement, translating complex findings into actionable insights
Partner with research teams to develop domain-specific evaluations that probe for emerging capabilities and potential risks
Build infrastructure to enable rapid iteration on evaluation design, supporting both automated and human-in-the-loop assessment approaches
Establish best practices and standards for evaluation development across the organization
Mentor team members and contribute to the growth of evaluation expertise at Anthropic
Coordinate evaluation efforts during critical training runs, ensuring comprehensive coverage and timely results
Contribute to research publications and external communications about evaluation methodologies and findings
You may be a good fit if you

Have experience designing and implementing evaluation systems for machine learning models, particularly large language models
Have demonstrated technical leadership experience, either formally or through leading complex technical projects
Are skilled at both systems engineering and experimental design, comfortable building infrastructure while maintaining scientific rigor
Have strong programming skills in Python and experience with distributed computing frameworks
Can translate between research needs and engineering constraints, finding pragmatic solutions to complex problems
Are results-oriented and thrive in fast-paced environments where priorities can shift based on research findings
Enjoy collaborative work and can effectively communicate technical concepts to diverse stakeholders
Care deeply about AI safety and the societal impacts of the systems we build
Have experience with statistical analysis and can draw meaningful conclusions from large-scale experimental data
Strong candidates may also have

Experience with evaluation during model training, particularly in production environments
Familiarity with safety evaluation frameworks and red teaming methodologies
Background in psychometrics, experimental psychology, or other fields focused on measurement and assessment
Experience with reinforcement learning evaluation or multi-agent systems
Contributions to open-source evaluation benchmarks or frameworks
Knowledge of prompt engineering and its role in evaluation design
Experience managing evaluation infrastructure at scale (thousands of experiments)
Published research in machine learning evaluation, benchmarking, or related areas
Representative projects

Designing comprehensive evaluation suites that assess models across hundreds of capability dimensions
Building real-time evaluation dashboards that surface critical insights during multi-week training runs
Developing novel evaluation approaches for emerging capabilities like multi-step reasoning or tool use
Creating automated systems to detect regression in model performance or safety properties
Implementing efficient evaluation sampling strategies that balance coverage with computational constraints
Collaborating with external partners to develop industry-standard evaluation benchmarks
Building infrastructure to support human evaluation at scale, including quality control and aggregation systems 
The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.

Annual Salary:
$300,000 - $405,000 USD
Logistics

Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different

We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!

Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process

Research Engineer, Pre-training
Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY
About Anthropic

Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.

Key Responsibilities:

Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development
Independently lead small research projects while collaborating with team members on larger initiatives
Design, run, and analyze scientific experiments to advance our understanding of large language models
Optimize and scale our training infrastructure to improve efficiency and reliability
Develop and improve dev tooling to enhance team productivity
Contribute to the entire stack, from low-level optimizations to high-level model design
Qualifications:

Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field
Strong software engineering skills with a proven track record of building complex systems
Expertise in Python and experience with deep learning frameworks (PyTorch preferred)
Familiarity with large-scale machine learning, particularly in the context of language models
Ability to balance research goals with practical engineering constraints
Strong problem-solving skills and a results-oriented mindset
Excellent communication skills and ability to work in a collaborative environment
Care about the societal impacts of your work
Preferred Experience:

Work on high-performance, large-scale ML systems
Familiarity with GPUs, Kubernetes, and OS internals
Experience with language modeling using transformer architectures
Knowledge of reinforcement learning techniques
Background in large-scale ETL processes
You'll thrive in this role if you:

Have significant software engineering experience
Are results-oriented with a bias towards flexibility and impact
Willingly take on tasks outside your job description to support the team
Enjoy pair programming and collaborative work
Are eager to learn more about machine learning research
Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects
Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research
View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights
Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.
Sample Projects:

Optimizing the throughput of novel attention mechanisms
Comparing compute efficiency of different Transformer variants
Preparing large-scale datasets for efficient model consumption
Scaling distributed training jobs to thousands of GPUs
Designing fault tolerance strategies for our training infrastructure
Creating interactive visualizations of model internals, such as attention patterns
At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.

If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!

The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.

Annual Salary:
$340,000 - $425,000 USD
Logistics

Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different

We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!

Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process

Research Engineer, Pretraining Scaling
San Francisco, CA
About Anthropic

Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the Role:

Anthropic's ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company's future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you'll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems.

This role lives at the boundary between research and engineering. You'll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can't wait for tomorrow.

Responsibilities: 

Own critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability
Debug and resolve complex issues across the full stack—from hardware errors and networking to training dynamics and evaluation infrastructure
Design and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance
Respond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams
Build and maintain production logging, monitoring dashboards, and evaluation infrastructure
Add new capabilities to the training codebase, such as long context support or novel architectures
Collaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams
Contribute to the team's institutional knowledge by documenting systems, debugging approaches, and lessons learned
You May Be a Good Fit If You:

Have hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems
Genuinely enjoy both research and engineering work—you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other
Are excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure
Thrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs
Excel at debugging complex, ambiguous problems across multiple layers of the stack
Communicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents
Are passionate about the work itself and want to refine your craft as a research engineer
Care about the societal impacts of AI and responsible scaling
Strong Candidates May Also Have: 

Previous experience training LLM’s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale
Contributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax)
Published research on model training, scaling laws, or ML systems
Experience with production ML systems, observability tools, or evaluation infrastructure
Background as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence
What Makes This Role Unique: 

This is not a typical research engineering role. The work is highly operational—you'll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends.

However, this operational intensity comes with extraordinary learning opportunities. You'll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You'll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can't be easily transferred. For people who thrive on this type of work, it's uniquely rewarding.

We're building a close-knit team of people who genuinely care about doing excellent work together. If you're someone who wants to be part of training the models that will define the future of AI—and you're excited about the full reality of what that entails—we'd love to hear from you.

Location:This role requires working in-office 5 days per week in San Francisco. 

Deadline to apply: None. Applications will be reviewed on a rolling basis.

The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.

Annual Salary:
$315,000 - $560,000 USD

Research Engineer / Research Scientist, Pre-training
Zürich, CH
About Anthropic

Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.

About the team

We are seeking passionate Research Scientists and Engineers to join our growing Pre-training team in Zurich. We are involved in developing the next generation of large language models. The team primarily focuses on multimodal capabilities: giving LLMs the ability to understand and interact with modalities other than text.

In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.

Responsibilities

In this role you will interact with many parts of the engineering and research stacks.

Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development
Independently lead small research projects while collaborating with team members on larger initiatives
Design, run, and analyze scientific experiments to advance our understanding of large language models
Optimize and scale our training infrastructure to improve efficiency and reliability
Develop and improve dev tooling to enhance team productivity
Contribute to the entire stack, from low-level optimizations to high-level model design
Qualifications & Experience

We encourage you to apply even if you do not believe you meet every single criterion. Because we focus on so many areas, the team is looking for both experienced engineers and strong researchers, and encourage anyone along the researcher/engineer spectrum to apply.

Degree (BA required, MS or PhD preferred) in Computer Science, Machine Learning, or a related field
Strong software engineering skills with a proven track record of building complex systems
Expertise in Python and deep learning frameworks
Have worked on high-performance, large-scale ML systems, particularly in the context of language modeling
Familiarity with ML Accelerators, Kubernetes, and large-scale data processing
Strong problem-solving skills and a results-oriented mindset
Excellent communication skills and ability to work in a collaborative environment
You'll thrive in this role if you

Have significant software engineering experience
Are able to balance research goals with practical engineering constraints
Are happy to take on tasks outside your job description to support the team
Enjoy pair programming and collaborative work
Are eager to learn more about machine learning research
Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects
Have ambitious goals for AI safety and general progress in the next few years, and you’re excited to create the best outcomes over the long-term
Sample Projects

Optimizing the throughput of novel attention mechanisms
Proposing Transformer variants, and experimentally comparing their performance
Preparing large-scale datasets for model consumption
Scaling distributed training jobs to thousands of accelerators
Designing fault tolerance strategies for training infrastructure
Creating interactive visualizations of model internals, such as attention patterns
If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!

Logistics

Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.

Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.

Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.

We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed.  Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.

How we're different

We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.

The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.

Come work with us!

Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process
